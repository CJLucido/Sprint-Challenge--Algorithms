#### Please add your answers to the **_Analysis of Algorithms_** exercises here.

## Exercise I

a)
The number of loops, runtime, will be n^2 because the iterator will be increased by n^2 each loop and n^2 goes into n^3 the same amount of times that n goes into n^2.

b)
Sum addition is constant. J multiplication is constant. The amount of times the equation does the while loop is approximately half of N. The amount of times the equation does the for loop is exactly proportional to n. The For Loop is O(n) BUT because we have slighlty increasing while loops for larger numbers of N, and the while loops slow down as we get to larger numbers (since they increase by the product of j Multiplied by 2), so O(log n). We have a O(log n) inside an O(n), I believe that would make this Linearithmic or O(n log n).

c)
The runtime complexity of a function that would otherwise be constant but is recursive...I believe that makes this Linear or O(n), it increases directly proportional to the input bunnies. (a side note, I believe if we added a cache it would act as only adding 2 to a known index and that would make it constant)

## Exercise II
